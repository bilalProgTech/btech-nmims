{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZzXx1gAAo+KHL/SWP+L9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/btech-nmims/blob/master/NN-DL/Lab-Work/20230806-Lab-3-BTech-NNDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content'\n",
        "!kaggle datasets download -d kausthubkannan/5-flower-types-classification-dataset"
      ],
      "metadata": {
        "id": "bAZ86ZGG5ROp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip *.zip"
      ],
      "metadata": {
        "id": "lPzPT2Rw6F59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN - Augmentation and Model"
      ],
      "metadata": {
        "id": "n0xC40gH8pqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Fz36PhUwP5Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "EGiJvTr66DlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_path_list = []\n",
        "for dirname, _, filenames in os.walk('/content/flower_images'):\n",
        "    for filename in filenames:\n",
        "        image_path_list.append(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "GbjGyjJL6x2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({'filename': image_path_list})\n",
        "train_df['class'] = train_df['filename'].str.split('/').str[-2]\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "uCxymjKIQYVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "oAJYPG5HQm2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['class'].value_counts()"
      ],
      "metadata": {
        "id": "ukkXgjVQRQ5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_feature = train_df['class'].unique()\n",
        "len(unique_feature)"
      ],
      "metadata": {
        "id": "Wnk9Jjh9GWe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_df.sample(16)\n",
        "files = sample['filename'].tolist()\n",
        "targets = sample['class'].tolist()"
      ],
      "metadata": {
        "id": "EAW93a9mE1LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "id": "umRmAKICFY2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrows = 4\n",
        "ncols = 4\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "for i, (img_path, target) in enumerate(zip(files, targets)):\n",
        "    sp = plt.subplot(nrows, ncols, i + 1)\n",
        "    sp.axis('Off')\n",
        "\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(target)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UZ9dZlzNCXWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    target_size=(256, 256),\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "id": "iPlHBNwXQCNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=(256, 256, 3)),\n",
        "                             tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                             tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(16, activation='relu'),\n",
        "                             tf.keras.layers.Dense(len(unique_feature), activation='softmax')])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "I65eAe0RBQRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-U3iseiVGsCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=10)"
      ],
      "metadata": {
        "id": "--bNDTe_Gzhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_generator)"
      ],
      "metadata": {
        "id": "HnU7eSDuG7GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "successive_outputs = [layer.output for layer in model.layers]\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(files[1], target_size=(256, 256))\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "print(targets[1])\n",
        "print(x.shape)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "print(x.shape)\n",
        "x /= 255\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "    if len(feature_map.shape) == 4:\n",
        "        n_features = feature_map.shape[-1]\n",
        "        print(feature_map.shape)\n",
        "        size = feature_map.shape[1]\n",
        "        display_grid = np.zeros((size, size * n_features))\n",
        "        for i in range(n_features):\n",
        "            x = feature_map[0, :, :, i]\n",
        "            x -= x.mean()\n",
        "            x /= x.std()\n",
        "            x *= 64\n",
        "            x += 128\n",
        "            x = np.clip(x, 0, 255).astype('uint8')\n",
        "            display_grid[:, i * size : (i + 1) * size] = x\n",
        "        scale = 20. / n_features\n",
        "        plt.figure(figsize=(scale * n_features, scale))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "metadata": {
        "id": "qHdK2U2ALCN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n",
        "                                                          rotation_range=40,\n",
        "                                                          width_shift_range=0.4,\n",
        "                                                          height_shift_range=0.4,\n",
        "                                                          shear_range=0.2,\n",
        "                                                          zoom_range=0.2,\n",
        "                                                          horizontal_flip=True,\n",
        "                                                          validation_split=0.2)\n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/flower_images',\n",
        "    class_mode = 'categorical',\n",
        "    target_size=(256,256),\n",
        "    subset = 'training')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    '/content/flower_images',\n",
        "    class_mode = 'categorical',\n",
        "    target_size=(256,256),\n",
        "    subset = 'validation')"
      ],
      "metadata": {
        "id": "RVFlpCzagaet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ],
      "metadata": {
        "id": "KixpxpffhvWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto Encoder - Image Compression"
      ],
      "metadata": {
        "id": "jmnesy8g8lq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "IVSSaNGW94zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/flower_images',\n",
        "    target_size=(256, 256),\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    class_mode='input')"
      ],
      "metadata": {
        "id": "TjsvWCh68oBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "class AutoEncoder(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "        ])\n",
        "\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "autoencoder = AutoEncoder()"
      ],
      "metadata": {
        "id": "8OnBOkBO-EZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.encoder.summary()"
      ],
      "metadata": {
        "id": "M7kcNwYZ-da7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.decoder.summary()"
      ],
      "metadata": {
        "id": "CxrbzG9n-gEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "9eVTG0mW-hzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = autoencoder.fit(train_generator, epochs=10)"
      ],
      "metadata": {
        "id": "kvPLgBQk_EL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = len(files)\n",
        "fig, axes = plt.subplots(num_images, 2, figsize=(8, 4*num_images))\n",
        "\n",
        "for i, image_path in enumerate(files):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
        "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = np.vstack([x])\n",
        "    x = x / 255\n",
        "    encoded = autoencoder.encoder(x).numpy()\n",
        "    decoded = autoencoder.decoder(encoded).numpy().reshape(-1, 256, 256, 3)\n",
        "\n",
        "    axes[i, 0].imshow(x[0])\n",
        "    axes[i, 0].set_title('Original')\n",
        "\n",
        "    axes[i, 1].imshow(decoded[0])\n",
        "    axes[i, 1].set_title('Decoded')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yNQ-LkKJ_L3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.keras.preprocessing.image.load_img('',\n",
        "                                            target_size=(256, 256))\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = np.vstack([x])\n",
        "x = x / 255\n",
        "\n",
        "encoded = autoencoder.encoder(x).numpy()\n",
        "decoded = autoencoder.decoder(encoded).numpy().reshape(-1, 256, 256, 3)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(x[0])\n",
        "plt.title('Original')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(decoded[0])\n",
        "plt.title('Decoded')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "img = tf.keras.preprocessing.image.array_to_img(decoded[0])\n",
        "img.save('decoded_image.jpg')"
      ],
      "metadata": {
        "id": "FY4VKN2cP4Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "class AutoEncoder(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = tf.keras.Sequential([\n",
        "        ])\n",
        "\n",
        "        self.decoder = tf.keras.Sequential([\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "autoencoder = AutoEncoder()"
      ],
      "metadata": {
        "id": "I1t5IlGVWrra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}