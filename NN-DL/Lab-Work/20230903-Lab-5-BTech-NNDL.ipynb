{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/btech-nmims/blob/master/NN-DL/Lab-Work/20230903-Lab-5-BTech-NNDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU2nSvteMqUR"
      },
      "source": [
        "# Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOlvU8CiN-DQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3WPRP6WWMpjp"
      },
      "outputs": [],
      "source": [
        "rnn_units = 2\n",
        "tf.keras.backend.clear_session()\n",
        "rnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(3, 1)),\n",
        "    tf.keras.layers.SimpleRNN(rnn_units, activation='tanh'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "rnn_model.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2otLeVI9cnb9"
      },
      "outputs": [],
      "source": [
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY__bakKOoen"
      },
      "outputs": [],
      "source": [
        "wx = rnn_model.get_weights()[0]\n",
        "wh = rnn_model.get_weights()[1]\n",
        "bh = rnn_model.get_weights()[2]\n",
        "wy = rnn_model.get_weights()[3]\n",
        "by = rnn_model.get_weights()[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmhQv229Ow55"
      },
      "outputs": [],
      "source": [
        "wx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vztEzZaIOw2A"
      },
      "outputs": [],
      "source": [
        "wh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFeUPM5NOwzA"
      },
      "outputs": [],
      "source": [
        "wy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMzsa3eAO2Z4"
      },
      "outputs": [],
      "source": [
        "bh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh3aDj_QO2UI"
      },
      "outputs": [],
      "source": [
        "by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWM8kErKO6gA"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1, 2, 3], [3, 4, 5]])\n",
        "x_input = np.reshape(x,(-1, 3, 1))\n",
        "model_yhat = rnn_model.predict(x_input)\n",
        "model_yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVkuQh_wh1t9"
      },
      "outputs": [],
      "source": [
        "x_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XRooB3_O6dT"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1, 2, 3]])\n",
        "x_input = np.reshape(x,(-1, 3, 1))\n",
        "rnn_units = 2\n",
        "wx = [[3, -4]]\n",
        "wy = [[-4], [2]]\n",
        "wh = [[4, -5], [-3, 2]]\n",
        "bh = 0\n",
        "by = 11\n",
        "'''\n",
        "Code for RNN\n",
        "'''\n",
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv75qufHUK76"
      },
      "outputs": [],
      "source": [
        "h0, h1, h2, h3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt2SFP8So_En"
      },
      "source": [
        "# Tokenization and Pad Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofbzMfTLowSj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saklKunLo-hX"
      },
      "outputs": [],
      "source": [
        "'''sentences = [\n",
        "    'i love deeplearning',\n",
        "    'I, love ai',\n",
        "    'You love deeplearning!',\n",
        "    'You think deeplearning is amazing'\n",
        "]'''\n",
        "\n",
        "sentences = ['This is an excellent movie', 'It was a wonderful movie',\n",
        "             'You should watch this brilliant movie', 'Exceptionally good movie',\n",
        "             'Horrible acting', 'I did not like the movie', 'I will not recommend you this movie', 'Pathetic and boring movie']\n",
        "\n",
        "# sentences = ['I love waffles', 'Smith loves cakes and waffles','Cakes are better than waffles','Lucy baked two cakes for a birthday party']\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9PsKNvSanG7"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnwyQbjfK6Hw"
      },
      "outputs": [],
      "source": [
        "test_sentences = [\n",
        "    'i really love deeplearning',\n",
        "    'ai is amazing and good'\n",
        "]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdSia2ZfJoQg"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 100, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KDrKFQ-Kvih"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4mo3JRYJoM5"
      },
      "outputs": [],
      "source": [
        "test_sentences = [\n",
        "    'i really love deeplearning',\n",
        "    'ai is amazing and good'\n",
        "]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EatgTVLUIcPo"
      },
      "outputs": [],
      "source": [
        "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F21m3mlEIcLR"
      },
      "outputs": [],
      "source": [
        "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8CTdbFzIcHZ"
      },
      "outputs": [],
      "source": [
        "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post', maxlen=4)\n",
        "padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE92jRKXanA5"
      },
      "outputs": [],
      "source": [
        "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post', maxlen=4, truncating='post')\n",
        "padded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoCF79-qLkCI"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwecTozFLj3J"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    # Positive Reviews\n",
        "\n",
        "    'This is an excellent movie',\n",
        "    'The move was fantastic I like it',\n",
        "    'You should watch it is brilliant',\n",
        "    'Exceptionally good',\n",
        "    'Wonderfully directed and executed I like it',\n",
        "    'Its a fantastic series',\n",
        "    'Never watched such a brillent movie',\n",
        "    'It is a Wonderful movie',\n",
        "\n",
        "    # Negtive Reviews\n",
        "\n",
        "    \"horrible acting\",\n",
        "    'waste of money',\n",
        "    'pathetic picture',\n",
        "    'It was very boring',\n",
        "    'I did not like the movie',\n",
        "    'The movie was horrible',\n",
        "    'I will not recommend',\n",
        "    'The acting is pathetic'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMFEeJy1LYhI"
      },
      "outputs": [],
      "source": [
        "sentiments = np.array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvH6OLQ6LYeo"
      },
      "outputs": [],
      "source": [
        "word_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
        "word_tokenizer.fit_on_texts(corpus)\n",
        "word_index = word_tokenizer.word_index\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qKt7q9QLYcL"
      },
      "outputs": [],
      "source": [
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "vocab_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik789M2pSfmM"
      },
      "outputs": [],
      "source": [
        "embedded_sequences = word_tokenizer.texts_to_sequences(corpus)\n",
        "print(embedded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QcXdzWkUZWZ"
      },
      "outputs": [],
      "source": [
        "longest_sentence = len(max(embedded_sequences, key=len))\n",
        "padded_sentences = tf.keras.preprocessing.sequence.pad_sequences(embedded_sequences, maxlen=longest_sentence, padding='post')\n",
        "print(padded_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLuN6OkkU6NQ"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 4\n",
        "tf.keras.backend.clear_session()\n",
        "embedding_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_length, embedding_dim,\n",
        "                              input_length=longest_sentence, name='embedding'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "embedding_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "embedding_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu_V-SNpU6Kp"
      },
      "outputs": [],
      "source": [
        "history = embedding_model.fit(padded_sentences, sentiments, epochs=50, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wVBveikU6IA"
      },
      "outputs": [],
      "source": [
        "embedding_model.evaluate(padded_sentences, sentiments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZxdk0R8Y0TH"
      },
      "outputs": [],
      "source": [
        "emb_weights = embedding_model.get_weights()[0]\n",
        "len(emb_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcSLDrYxY0Qp"
      },
      "outputs": [],
      "source": [
        "emb_weights[16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0YzzxzaLYZy"
      },
      "outputs": [],
      "source": [
        "emb_weights[23]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4oEO4c-ZMAg"
      },
      "outputs": [],
      "source": [
        "emb_weights[35]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DhyCQpdWTnNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = plt.cm.jet(np.linspace(0, 1, len(emb_weights)))\n",
        "\n",
        "custom_colors = ['red', 'brown', 'pink', 'green', 'blue', 'purple', 'orange',\n",
        "                 'cyan', 'magenta', 'gray', 'gold', 'lime', 'indigo',\n",
        "                 'turquoise', 'violet', 'teal', 'maroon', 'navy', 'olive',\n",
        "                 'sienna', 'salmon', 'lavender', 'coral', 'khaki', 'slategray',\n",
        "                 'peru', 'plum', 'orchid', 'deeppink', 'chocolate',\n",
        "                 'midnightblue', 'darkseagreen', 'tomato', 'dodgerblue',\n",
        "                 'darkslategray', 'royalblue', 'seashell', 'hotpink',\n",
        "                 'mediumvioletred', 'darkolivegreen', 'darkorange',\n",
        "                 'goldenrod', 'saddlebrown']\n",
        "\n",
        "for i, vocab_it in zip(range(len(emb_weights)), word_tokenizer.word_index.keys()):\n",
        "    x = emb_weights[i, 0]\n",
        "    y = emb_weights[i, 1]\n",
        "    color = custom_colors[i % len(custom_colors)]\n",
        "    plt.scatter(x, y, label=vocab_it, color=color)\n",
        "\n",
        "plt.title(\"Embedding Trained Weights\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.grid(True)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DX8Q7KjhTSrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU9EsB-GLmKB"
      },
      "source": [
        "# Simple RNN for NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFGemAvULC9C",
        "outputId": "9e8b2a03-d906-499f-aec5-b850d7377d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading mcdonalds-store-reviews.zip to /content\n",
            "  0% 0.00/1.78M [00:00<?, ?B/s]\n",
            "100% 1.78M/1.78M [00:00<00:00, 42.8MB/s]\n",
            "Archive:  mcdonalds-store-reviews.zip\n",
            "  inflating: McDonald_s_Reviews.csv  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "!kaggle datasets download -d nelgiriyewithana/mcdonalds-store-reviews\n",
        "!unzip *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsPhC_2Cam-E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x85dUGqTbXno"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_colwidth\", 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oODZF8rpcWW"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/McDonald_s_Reviews.csv', encoding='latin-1')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzO9IQGGLtzc"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q7Zx0-zLu9b"
      },
      "outputs": [],
      "source": [
        "data = data[['review', 'rating']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN5xMEqmawJH"
      },
      "outputs": [],
      "source": [
        "data[\"rating\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6UcjJMSL9ml"
      },
      "outputs": [],
      "source": [
        "data['rating'] = data['rating'].str[0].astype('int64')\n",
        "data = data[data['rating'].isin([1, 5])]\n",
        "data['rating'] = np.where(data['rating']==1, 1, 0)\n",
        "data[\"rating\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfLAborea5iH"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
        "    return ' '.join(no_stopword_text)\n",
        "\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "\n",
        "def remove_nonenglish(text):\n",
        "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha())\n",
        "\n",
        "def remove_handles(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "    return input_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIEFkWfcenQF"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = remove_handles(text, '@[\\w]*')\n",
        "    text = re.sub(\"\\'\", \"\", text)\n",
        "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
        "    text = re.sub(\"http\\S+|www.\\S+\",\"\", text)\n",
        "    text = text.lower()\n",
        "    text = ' '.join([w for w in text.split() if len(w)>=2])\n",
        "    text = remove_stopwords(text)\n",
        "    text = remove_nonenglish(text)\n",
        "    words = text.split()\n",
        "    text = \" \".join(sorted(set(words), key=words.index))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hJ8ud-Ja5d3"
      },
      "outputs": [],
      "source": [
        "data['clean_review'] = data['review'].apply(lambda x: clean_text(x))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAjjW3qQawGu"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qo7vGgwawCW"
      },
      "outputs": [],
      "source": [
        "all_words = ' '.join([text for text in data[data['rating']==1]['clean_review']])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR6SnW2Dhvd_"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.2, random_state=12)\n",
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hktEqIZdN60k"
      },
      "outputs": [],
      "source": [
        "train[\"rating\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyjg4Hh2N7RU"
      },
      "outputs": [],
      "source": [
        "test[\"rating\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZGzwgbbjzkl"
      },
      "outputs": [],
      "source": [
        "y_train = train['rating']\n",
        "y_test = test['rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQl9iKDgav_3"
      },
      "outputs": [],
      "source": [
        "train_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
        "train_tokenizer.fit_on_texts(train['clean_review'].values)\n",
        "train_word_index = train_tokenizer.word_index\n",
        "print(train_word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qneTSsUHhYbA"
      },
      "outputs": [],
      "source": [
        "vocab_length = len(train_word_index) + 1\n",
        "vocab_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAIK-nTYhYXW"
      },
      "outputs": [],
      "source": [
        "train_sequences = train_tokenizer.texts_to_sequences(train['clean_review'].values)\n",
        "len(train_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaGGBfzJhYUW"
      },
      "outputs": [],
      "source": [
        "test_sequences = train_tokenizer.texts_to_sequences(test['clean_review'].values)\n",
        "len(test_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Xc_JO4hYRP"
      },
      "outputs": [],
      "source": [
        "longest_sentence = len(max(train_sequences, key=len))\n",
        "train_padded_seqeunces = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, padding='post', maxlen=longest_sentence, truncating='post')\n",
        "test_padded_seqeunces = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, padding='post', maxlen=longest_sentence, truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llawjVjKpATF"
      },
      "outputs": [],
      "source": [
        "longest_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgA-mymBpC1v"
      },
      "outputs": [],
      "source": [
        "vocab_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5UlL8ZLbbO6"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 8\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_length, embedding_dim,\n",
        "                              input_length=longest_sentence),\n",
        "    tf.keras.layers.SimpleRNN(64, activation='tanh', return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(32, activation='tanh'),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYVHAN9mehGJ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_padded_seqeunces, y_train, epochs=10,\n",
        "                    validation_data=(test_padded_seqeunces, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRlQMwGlmexW"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_padded_seqeunces, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz-nSyihmReU"
      },
      "outputs": [],
      "source": [
        "test_prob = model.predict(test_padded_seqeunces)\n",
        "test_pred = np.where(test_prob > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARWjNSA5ljKZ"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX-8__2mmay6"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test, test_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVffNTiRVsapnN9M5kfHbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}